{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "- **Establish your baseline score.**\n",
    "- Fit linear regression. Look at your coefficients. Are any of them wildly overblown?\n",
    "    **For every 1 unit increase in $x_i$, we expect SalePrice to increase by $\\beta_i$.**\n",
    "- Fit lasso/ridge/elastic net with default parameters.\n",
    "- Go back and remove features that might be causing issues in your models.\n",
    "- Tune hyperparameters.\n",
    "- **Identify a production model.** (This does not have to be your best performing Kaggle model, but rather the model that best answers your problem statement.)\n",
    "- Refine and interpret your production model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access scaled & Test/Train-Split variables from Notebook: 02_Preprocessing_and_Feature_Engineering\n",
    "%store -r X_train\n",
    "%store -r X_test\n",
    "%store -r X_train_ss\n",
    "%store -r X_test_ss\n",
    "%store -r y_train\n",
    "%store -r y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate linear regression model\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LassoCV and RidgeCV, fit with default parameters\n",
    "lasso = LassoCV(n_alphas=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeCV(alphas=np.linspace(.1, 10, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Establish Baseline Score: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636902331607144"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Cross-Val: Baseline Score\n",
    "lm_scores = cross_val_score(lm, X_train_ss, y_train, cv=5)\n",
    "lm_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636457522513329"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use cross_val_score to evaluate LassoCV\n",
    "lasso_scores = cross_val_score(lasso, X_train_ss, y_train, cv=5)\n",
    "lasso_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7639045038601507"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use cross_val_score to evaluate RidgeCV\n",
    "ridge_scores = cross_val_score(ridge, X_train_ss, y_train, cv=5)\n",
    "ridge_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So which model performed best?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fit the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearReg: Train=0.7777852697275695, Test=0.8222516669009068, \n",
      "Cross-Val: Train=0.7636902331607144, Test=0.8272680836096882\n"
     ]
    }
   ],
   "source": [
    "# Fit the linear regression to chosen scaled-features\n",
    "lm.fit(X_train_ss, y_train)\n",
    "\n",
    "# 1. Train Score\n",
    "lm_train_score = lm.score(X_train_ss,y_train)\n",
    "# 2. Test Score\n",
    "lm_test_score = lm.score(X_test_ss, y_test)\n",
    "# 4. Cross-Val \"Test\" Score\n",
    "lm_test_scores = cross_val_score(lm, X_test_ss, y_test, cv=5)\n",
    "\n",
    "print(f'LinearReg: Train={lm_train_score}, Test={lm_test_score}, \\nCross-Val: Train={lm_scores.mean()}, Test={lm_test_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV:   Train=0.7777706441649628, Test=0.8218238760027691, \n",
      "Cross-Val: Train=0.7636457522513329, Test=0.8275888228568269\n"
     ]
    }
   ],
   "source": [
    "# Fit the lasso regression to chosen scaled-features\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# 1. Train Score\n",
    "lasso_train_score = lasso.score(X_train_ss,y_train)\n",
    "# 2. Test Score\n",
    "lasso_test_score = lasso.score(X_test_ss, y_test)\n",
    "# 4. Cross-Val \"Test\" Score\n",
    "lasso_test_scores = cross_val_score(lasso, X_test_ss, y_test, cv=5)\n",
    "\n",
    "print(f'LassoCV:   Train={lasso_train_score}, Test={lasso_test_score}, \\nCross-Val: Train={lasso_scores.mean()}, Test={lasso_test_scores.mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV:   Train=0.7777766125446623, Test=0.8222867156281176, \n",
      "Cross-Val: Train=0.8277320497245618, Test=0.8277320497245618\n"
     ]
    }
   ],
   "source": [
    "# Fit the lasso regression to chosen scaled-features\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# 1. Train Score\n",
    "ridge_train_score = ridge.score(X_train_ss,y_train)\n",
    "# 2. Test Score\n",
    "ridge_test_score = ridge.score(X_test_ss, y_test)\n",
    "# 4. Cross-Val \"Test\" Score\n",
    "ridge_test_scores = cross_val_score(ridge, X_test_ss, y_test, cv=5)\n",
    "\n",
    "print(f'RidgeCV:   Train={ridge_train_score}, Test={ridge_test_score}, \\nCross-Val: Train={ridge_scores.mean()}, Test={ridge_test_scores.mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***In order to evaluate the model:***\n",
    "- Obtain three \"scores\" : \n",
    "\n",
    "    1. Train\n",
    "    \n",
    "    2. Test\n",
    "    \n",
    "    3. Cross-Val (the avg of five Test-scores) - This will serve as a baseline $R^2$ for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If Test and Cross Val are similar, then you have representative test set. \n",
    "#If they diverge, then you probably have a large sampling error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year Remod/Add     6163.780925\n",
       "Year Built         8968.494023\n",
       "1st Flr SF         6612.027035\n",
       "Total Bsmt SF      5744.896014\n",
       "Garage Area       10243.796560\n",
       "Gr Liv Area       22860.742323\n",
       "Overall Qual      29022.187381\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The `lm` object contains our model's coefficients\n",
    "pd.Series(lm.coef_, index=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181807.08072916666"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the y-intercept.\n",
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "- Go back and remove features that might be causing issues in your models.\n",
    "- Tune hyperparameters.\n",
    "- **Identify a production model.** (This is the model that best answers your problem statement.)\n",
    "- Refine and interpret your production model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
